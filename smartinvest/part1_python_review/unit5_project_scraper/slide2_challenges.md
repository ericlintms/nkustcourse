# 投影片 2/4: 爬蟲的禮儀與挑戰

## 爬蟲的禮儀 (Robots.txt)

* 在爬取一個網站前，應該先檢查其 `robots.txt` 檔案 (例如: `https://www.google.com/robots.txt`)。
* 這個檔案會告訴爬蟲，網站的哪些部分是不希望被自動抓取的。
* **尊重網站的規則是好公民的表現。**

---

## 爬蟲的挑戰

1. **被網站阻擋**:
    * 許多網站會偵測你是否為機器人。如果請求頻率太高，或沒有像瀏覽器一樣的標頭 (Headers)，就可能被阻擋。
    * **解法**: 在請求中加入 `User-Agent` 標頭，模擬瀏覽器。

2. **網頁結構變更**:
    * 網站隨時可能改版，導致你用來定位資料的 HTML 標籤或 CSS class 失效。
    * **解法**: 這無可避免，只能在爬蟲失效時，手動更新程式碼中的定位規則 (Selector)。

3. **動態載入內容 (JavaScript)**:
    * 有些資料是透過 JavaScript 在頁面載入後才動態填上的。`requests` 函式庫只會抓取原始的 HTML，無法執行 JavaScript。
    * **解法**: 需要使用更進階的工具，如 `Selenium` 或 `Playwright`，它們可以實際驅動一個瀏覽器來抓取頁面。